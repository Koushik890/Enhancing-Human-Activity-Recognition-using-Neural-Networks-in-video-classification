# Enhancing-Human-Activity-Recognition-using-Neural-Networks-in-video-classification ğŸ˜º

## Overview ğŸ¾

Meow! Welcome to the Human Action Recognition project. This project uses a combination of Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) to identify and classify human actions in videos. These actions could be anything from walking, running, dancing, etc.

## Technologies Used ğŸ˜¸

* Python
* TensorFlow
* Keras
* OpenCV

## How to Run This Project ğŸ˜¼

1. Clone this repository: `git clone https://github.com/Koushik890/Enhancing-Human-Activity-Recognition-using-Neural-Networks-in-video-classification`
2. Run the Jupyter notebook: `jupyter notebook Human_Action_Recogntion_using_CNN_+_LSTM.ipynb`

## Project Structure ğŸ±

* `Human_Action_Recogntion_using_CNN_+_LSTM.ipynb`: This is the main Jupyter notebook where all the magic happens.

## Results and Discussion ğŸ™€

This model can accurately classify different human actions in videos, which has a wide range of applications from video surveillance to creating more interactive virtual reality experiences. 

## Future Work ğŸ˜º

There's always room for improvement! Future updates may include increasing the accuracy of the model, integrating more complex actions, and possibly deploying the model for real-time action recognition.

## Contributing ğŸ¾

Meow! Feel free to fork this repository and make your own changes. Pull requests are welcome.

## Contact ğŸ¾

For any questions or feedback, please meow at us by opening an issue. Happy coding!

